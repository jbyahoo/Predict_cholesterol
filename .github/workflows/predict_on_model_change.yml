name: Predict on new data or with new model

on: 
  push:
    branches:
      - main
    paths:
      - 'data/raw/test_cholesterol.xlsx'
      - 'data/processed/test_cholesterol.xlsx'
      - 'ARISA_DSML/predict.py'
      - 'models/cholesterol-pred-bclass.cbm'
  workflow_dispatch:

jobs:
  preprocess:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"

      - name: Install dependencies
        run: make requirements

      - name: Configure Kaggle credentials
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p ~/.kaggle
          echo '{"username":"'$KAGGLE_USERNAME'","key":"'$KAGGLE_KEY'"}' > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Run preprocessing
        run: make preprocess

      - name: Log model to MLflow
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        run: python log_model.py

      - name: Verify model path
        run: |
          ls -lah models/cholesterol-pred-bclass.cbm
          test -f models/cholesterol-pred-bclass.cbm || exit 1

      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed
          retention-days: 3

  predict:
    runs-on: ubuntu-latest
    needs: preprocess
    permissions:
      contents: write
    steps: 
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed

      - name: Verify downloaded files
        run: ls -lah data/processed

      - name: Set up Python
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"

      - name: Install dependencies
        run: make requirements

      - name: Resolve challenge
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          mlflow experiments create -n cholesterol-pred 2>/dev/null || true
          make resolve

      - name: Predict on test data
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: make predict

      - name: Verify predictions
        run: ls -lah models/preds.csv

      - name: Upload predictions
        uses: actions/upload-artifact@v4
        with:
          name: predictions
          path: models/preds.csv
          retention-days: 3

      - name: Install Azure CLI
        run: curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Upload model to Azure Storage
        env: 
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
        run: |
          az storage blob upload \
            --file models/preds.csv \
            --container-name "$AZURE_STORAGE_CONTAINER" \
            --name "predictions/$(date +%Y-%m-%d)/preds.csv" \
            --connection-string "$AZURE_STORAGE_CONNECTION_STRING"
