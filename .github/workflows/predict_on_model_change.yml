name: Cholesterol Prediction Pipeline

on: 
  push:
    branches: [main]
    paths:
      - 'data/raw/test_cholesterol.xlsx'
      - 'ARISA_DSML/predict.py'
      - 'models/cholesterol-pred-bclass.cbm'
  workflow_dispatch:

jobs:
  preprocess:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
        working-directory: ${{ github.workspace }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"
          cache: 'pip'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y unzip

      - name: Create directory structure
        run: mkdir -p data/{raw,processed} models

      - name: Configure Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p ~/.kaggle
          echo "{\"username\":\"$KAGGLE_USERNAME\",\"key\":\"$KAGGLE_KEY\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          make requirements

      - name: Run preprocessing pipeline
        run: |
          make preprocess
          echo "Model generation verification:"
          ls -l models/cholesterol-pred-bclass.cbm

      - name: Validate artifacts
        run: |
          [ -f models/cholesterol-pred-bclass.cbm ] || { echo "Model file missing!"; exit 1; }
          [ -f data/processed/test_cholesterol.xlsx ] || { echo "Processed data missing!"; exit 1; }

      - name: Log model to MLflow
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        run: |
          echo "MLflow Version: $(mlflow --version)"
          python ARISA_DSML/log_model.py

      - name: Archive artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-artifacts
          path: |
            data/processed/
            models/
          retention-days: 7

  predict:
    runs-on: ubuntu-latest
    needs: preprocess
    permissions:
      contents: write
    env:
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
      AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
    steps:
      - name: Retrieve artifacts
        uses: actions/download-artifact@v4
        with:
          name: pipeline-artifacts
          path: .

      - name: Validate workspace
        run: |
          echo "Current directory: $(pwd)"
          ls -l models/cholesterol-pred-bclass.cbm
          ls -l data/processed/test_cholesterol.xlsx

      - name: Set up Python
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"

      - name: Install prediction dependencies
        run: |
          pip install -r requirements.txt
          pip install azure-storage-blob

      - name: Execute predictions
        run: |
          make predict
          echo "Prediction file contents:"
          head -n 5 models/preds.csv

      - name: Deploy to Azure
        run: |
          az storage blob upload \
            --file models/preds.csv \
            --container-name "$AZURE_STORAGE_CONTAINER" \
            --name "predictions/$(date +%Y%m%d)/preds.csv" \
            --connection-string "$AZURE_STORAGE_CONNECTION_STRING" \
            --overwrite

      - name: Archive results
        uses: actions/upload-artifact@v4
        with:
          name: prediction-results
          path: models/preds.csv
          retention-days: 30
