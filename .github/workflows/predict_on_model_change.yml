name: Predict on new data or with new model

on: 
  push:
    branches:
      - main
    paths:
      - 'data/raw/test_cholesterol.xlsx'
      - 'data/processed/test_cholesterol.xlsx'
      - 'ARISA_DSML/predict.py'
      - 'models/catboost_model_cholesterol.cbm'
  workflow_dispatch:

jobs:
  preprocess:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create directories
        run: |
          mkdir -p data/raw
          mkdir -p data/processed

      - name: Set up Python
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"

      - name: Install Kaggle API
        run: pip install kaggle

      - name: Configure Kaggle credentials
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p "$HOME/.kaggle"
          echo "{\"username\":\"$KAGGLE_USERNAME\",\"key\":\"$KAGGLE_KEY\"}" > "$HOME/.kaggle/kaggle.json"
          chmod 600 "$HOME/.kaggle/kaggle.json"
          echo "KAGGLE_CONFIG_DIR=$HOME/.kaggle" >> $GITHUB_ENV

      - name: Download dataset
        run: |
          kaggle datasets download -d joannborkowska/cholesterol-supplementation-classification -p data/raw/
          unzip data/raw/*.zip -d data/raw/

      - name: Verify download
        run: ls -la data/raw/
  predict:
    runs-on: ubuntu-latest
    needs: preprocess
    permissions:
      contents: write  # This gives the token write access to the repository contents
    steps: 
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed
      - name: Set up Python
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"
      - name: Install dependencies
        run: make requirements
      - name: Resolve challenge
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: make resolve
      - name: Predict on test data
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: make predict
      - name: Upload predictions
        uses: actions/upload-artifact@v4
        with:
          name: predictions
          path: models/preds.csv

      - name: Install Azure CLI
        run: curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Upload model to Azure Storage
        env: 
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
          AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
        run: |
          az storage blob upload \
          --file models/preds.csv \
          --container-name "$AZURE_STORAGE_CONTAINER" \
          --name "predictions/preds.csv" \
          --connection-string "$AZURE_STORAGE_CONNECTION_STRING"

